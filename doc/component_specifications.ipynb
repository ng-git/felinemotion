{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Component Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Software components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Component 1: Visualization manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload video component lets users to upload the video with cat in it. After clicking \"Upload\", the video will be ready for preprocessing. \n",
    "<br>\n",
    "Input: Video with cat face and meowing in mp4 format\n",
    "<br>\n",
    "Output: One audio and three images with cat face\n",
    "<br>\n",
    "\n",
    "##### User interface (Minh)\n",
    "\n",
    "###### main.py\n",
    "\n",
    "The main script runs HTML webpage for user interaction and receives user input. After receiving the video input from the user through the webpage, the main script run video_input.py, which extracts audio data and image frames.\n",
    "\n",
    "Secondly, it run sound analysis components to analyze the sound data. It would also run Image analysis components to obtain three random cat images from the frames. The script then shows the user those cropped images and request user’s selection for the best one for Emotion analysis.\n",
    "\n",
    "After receiving user’s input for best image, the script would run the SVM model using the analyzed audio data and selected image. The model’s output, which would be determined emotion, then would be delivered to the user through the webpage.\n",
    "\n",
    "##### Video_input.py\n",
    "<br>\n",
    "This module contain a single function. Its job is to receive a MP4 video as input, and return extracted sound data and image frames.\n",
    "\n",
    "The module first extract the sound data and then save it in WAV format. Then, it creates a directory /frames to store the frames that are about to be collected. Afterward, using a for loop, each frame would be picked and save into the directory in PNG format, ready to be analyzed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Component 2: Data manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This component would process the raw image and audio data into analyzable dataset. \n",
    "<br>\n",
    "Input: raw audio and image data\n",
    "<br>\n",
    "Output: analyzable audio and image data\n",
    "\n",
    "##### Image analysis (JerYo)\n",
    "\n",
    "###### image_analysis.py\n",
    "\n",
    "After extracted the MP4 video into images frames. This module first convert the image into grayscale, then the cat face can be detected using Haar Cascade Classifier. After detecting, the images with cat face will then be cut into a constant size and saved in a folder.\n",
    "\n",
    "###### random_pick_3.py\n",
    "\n",
    "In order to provide better images with cat face. We decide to let the user to select three pictures with cats included from the video. The module will randomly select three images from the cat face image folder.\n",
    "\n",
    "###### image_output.py\n",
    "\n",
    "After letting the user select the best image from the three pictures. The image will then been compressed and converted into a csv file for next step modeling.\n",
    "\n",
    "##### Audio analysis (Weishi)\n",
    "\n",
    "###### audio_input.py\n",
    "\n",
    "This module contains the function that read in user input sound and save as audio_test.csv for fitting the model.\n",
    "The function, audio_input, read input of the user input wav file then attach it to the whole data set and run PCA to reduce features. It will save the converted and reduced user input as audio_test.csv for next step SVM. The audio_test.csv is a 1D array with 20 features extracted from the wav file. \n",
    "\n",
    "###### audio_create_model.py\n",
    "\n",
    "This module contains a function that use principal component analysis to reduce feature size and then create a csv file that contains all features from the training data for SVM. \n",
    "The function, create_model, first takes input of the folder directory that contains all raw wav files from youtube videos, and apply mel-spectrogram to the raw csv files. The original converted data contains over 12000 features that are impossible to build model. A principle component analysis was used to select top 20 features. Then the function will save all data to a csv file called full.csv. The full.csv is a 20 by N matrix (N = number of samples). It will also be needed for analyzing user input. \n",
    "\n",
    "\n",
    "###### audio_training.py\n",
    "\n",
    "This module contains some essential functions for sound analysis. All modules in this software need to import this module for proper usage. Three functions are included: convert_mel_one, save_csv_raw, add_label. \n",
    "Convert_mel_one will convert one single wav file to 1D numerical data using mel-spectrogram analysis. The return is 1D array that contains all features (>12000). \n",
    "Save_csv_raw will convert batch wav files in a directory and save all files in an M by N matrix (M = number of features from one wav file, N = number of samples) as audio_raw.csv. The audio_raw.csv file will be saved in the same folder as the raw wav files. The function also returns the label of each wav file which will be used in the next step. \n",
    "Add_label is a simple function that generates 20 alphabets as feature names for SVM. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Component 3: Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After user select one cat face image, both audio and image data will be prompt into the trained SVM model. And return the cat emotion.\n",
    "<br>\n",
    "Input: one audio csv and one image csv \n",
    "<br>\n",
    "Output: cat emotion (happy, angry, hungry)\n",
    "\n",
    "##### Model training and classification (Yue)\n",
    "\n",
    "###### svm.py\n",
    "\n",
    "This component includes the SVM model to do the emotion classification. Two functions are included in this module: csv_merge and classification. \n",
    "\n",
    "The csv_merge function is to import the image and audio dataset separately and merge them on ‘catID’. An user_csv file will be output into userData folder for the classification. If the selected_image.csv and audio_test.csv cannot be found in the current working directory, a value error message will raise as “Invalid input file”. \n",
    "\n",
    "The classification function is to train the linear SVC model based on the training data and classify the cat emotion. First, image and audio training datasets will be imported and merged based on the ‘catID’. Linear Support Vector Classification (LinearSVC) is one of the models in Support vector machines (SVMs) that able to perform multi-class classification on a dataset. Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples. For the LinerSVC model, Tolerance for stopping criteria is 1e-5, and the seed of the pseudo random number generator to use when shuffling the data for the dual coordinate descent is 0. Then the user data (userData/user_csv.csv) will fit into the trained model to get the emotion classification. If the user_csv.csv file cannot be found in the working directory, a value error message will raise as “Invalid input file”. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Interactions to accomplish use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Interaction 1: Upload video \n",
    "The component accepts the video input from the user. Unless it's the required file type (.mp4), it will prevent the user from proceeding to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Interaction 2: Select one cat image out of three cat images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The component accepts the three cat face images and prompt them into the screen so that user could select the one that they want to use in the analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Interaction 3: Evaluate cat emotion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The component accepts the one audio csv file and one image csv file from previous process. After user click confirm button under the three cat face images, the two csv files will be prompt into the svm analysis part. Then the reuslt of the cat emotion will show in the screen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preliminary plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A list of tasks in priority order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the video;\n",
    "2. Dataset preparation:\n",
    "    2.1 Extract image and audio dataset from the video dataset;\n",
    "    2.2 Capture the image with cat face;\n",
    "    2.3 Get the audio clip with meowing;\n",
    "    2.4 Register cat face image into 48*48 greyscale pixels;\n",
    "    2.5 Get the frequency of the audio clip;\n",
    "    2.6 Merge the image and audio dataset by catID;\n",
    "3. Data analysis using SVM;\n",
    "4. Develop the upload function;\n",
    "5. Develop the evaluation function;\n",
    "6. Code review;\n",
    "7. Finalize the documentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
